{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando GANs com imagens\n",
    "\n",
    "Apesar de já termos utilizado GANs com dados mais simples, aplicar esses modelos em dados mais complexos tem seus próprios desafios.\n",
    "\n",
    "Nesta aula treinaremos um modelo GAN na base de dados MNIST, tentando fazer com que o gerador crie amostras sintéticas de imagens de dígitos.\n",
    "\n",
    "O primeiro passo é carregar a base de treinamento, que faremos através do [tensorflor_datasets](https://www.tensorflow.org/datasets?hl=pt-br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "image, label = tfds.as_numpy(tfds.load(\n",
    "    'mnist',\n",
    "    split='train', \n",
    "    batch_size=-1, \n",
    "    as_supervised=True,\n",
    "))\n",
    "train_image = image\n",
    "train_labels = label\n",
    "image, label = tfds.as_numpy(tfds.load(\n",
    "    'mnist',\n",
    "    split='test', \n",
    "    batch_size=-1, \n",
    "    as_supervised=True,\n",
    "))\n",
    "\n",
    "test_image = image\n",
    "test_labels = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de treinamento contém imagens (28x28x1 - ou seja, preto e branco) com dígitos escritos e sua respectiva label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label[:3])\n",
    "plt.imshow(image[0].reshape(28,28),cmap=\"gray\"), plt.figure()\n",
    "plt.imshow(image[1].reshape(28,28),cmap=\"gray\"), plt.figure()\n",
    "plt.imshow(image[2].reshape(28,28),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A label não interessa para nossa aplicação de geração automatizada, portanto preparamos nossa base de treinamento e teste apenas com as imagens. Também serão normalizadas as imagens para que tenham valores entre -1 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Implemente uma rotina de normalização em que train_dataset seja normalizado entre -1 e 1 \n",
    "# (dica: imagens preto e branco não normalizadas vão de 0 a 255)\n",
    "train_dataset = #Seu Codigo normalizando train_image\n",
    "test_dataset = #Seu Codigo normalizando test_image\n",
    "train_dataset = train_dataset.reshape((len(train_dataset),28,28,1))\n",
    "test_dataset = test_dataset.reshape((len(test_dataset),28,28,1))\n",
    "\n",
    "#Aqui deve ser impresso (60000, 28, 28, 1)\n",
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante o treinamento vai ser útil visualizar as imagens que estão sendo geradas pela rede, portanto precisamos de uma função para facilitar a visualização das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_images(samples):\n",
    "    plt.close()\n",
    "    for i in range(25):\n",
    "        # define subplot\n",
    "        plt.subplot(5, 5, 1 + i)\n",
    "        # turn off axis\n",
    "        plt.axis('off')\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(samples[i].reshape((28,28)), cmap='gray_r')\n",
    "    plt.show()\n",
    "#As 25 primeiras imagens serão impressas\n",
    "print_images(train_dataset[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos então construir nossa GAN conforme aprendemos na última aula. Dado que estamos lidando com imagens, podemos nos aproveitar de arquiteturas especializadas para o processamento de imagens, tais como CNNs. Mas inicialmente, construa o modelo baseando-se primariamente em \"fully-connected layers\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Softmax\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Conv2DTranspose, LeakyReLU, Dropout, Input\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, BatchNormalization,Reshape, Activation, Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import initializers\n",
    "import numpy as np\n",
    "\n",
    "def gan_generator_model(dim_random):\n",
    "    model = Sequential()\n",
    "    #Sua arquitetura para o gerador (a saida deve ser no formato (?, 28, 28, 1))\n",
    "    return model\n",
    "\n",
    "def gan_discriminator_model():\n",
    "    model = Sequential()\n",
    "    #Sua arquitetura para o discriminador (entrada (?, 28, 28, 1) e saida com 1 dimensao entre 0 e 1)\n",
    "    return model\n",
    "\n",
    "def define_gan(generator, discriminator):\n",
    "    # connect generator and discriminator\n",
    "    discriminator.trainable = False\n",
    "    ganInput = Input(shape=(dim_random_vector,))\n",
    "    x = generator(ganInput)\n",
    "    ganOutput = discriminator(x)\n",
    "    gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return gan\n",
    "\n",
    "dim_random_vector = 100\n",
    "generator = gan_generator_model(dim_random_vector)\n",
    "generator.summary()\n",
    "discriminator = gan_discriminator_model()\n",
    "opt = # Otimizador para o Discriminador\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "discriminator.summary()\n",
    "gan = define_gan(generator, discriminator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de realizar o treinamento, vamos também gerar funções intermediárias para a geração de batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_discriminator(generator,batch_size, treino = True):\n",
    "    half_batch = int(batch_size/2)\n",
    "    \n",
    "    batch = np.zeros((batch_size, 28, 28, 1))\n",
    "    batch_y = np.zeros(batch_size)\n",
    "    \n",
    "    #Pega exemplos aleatoriamente da base de treinamento ou teste\n",
    "    if treino:\n",
    "        random_indices = np.random.choice(len(train_dataset), size=half_batch, replace=False)\n",
    "        batch[:half_batch, :, :, :] = train_dataset[random_indices, :, :, ]\n",
    "    else:\n",
    "        random_indices = np.random.choice(len(test_dataset), size=half_batch, replace=False)\n",
    "        batch[:half_batch, :, :, :] = test_dataset[random_indices, :, :, :]\n",
    "    #Labels das instâncias reais já são 0, entao nao há necessidade de mudar batch_y\n",
    "    \n",
    "    # A variável aleatória de entrada do gerador vai seguir uma distribuição normal\n",
    "    batch[half_batch:, :] = generator.predict(np.random.normal(0, 1, size=[half_batch, dim_random_vector]))\n",
    "    batch_y[half_batch:] += 1. \n",
    "    return batch, batch_y\n",
    "\n",
    "def generate_batch_gan(batch_size):\n",
    "    x_gan = np.random.normal(0, 1, size=[batch_size, dim_random_vector])\n",
    "    #Neste caso criamos labels invertidos para os exemplos falsos, porque a funcao de custo\n",
    "    # do gerador é o inverso do discriminador\n",
    "    y_gan = np.zeros((batch_size)) \n",
    "    return x_gan,y_gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos realizar o treinamento da GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_gan(generator,discriminator,gan):\n",
    "    batch_size = 128\n",
    "    epochs = 20000\n",
    "\n",
    "    test_size = 100\n",
    "    half_test = int(test_size /2)\n",
    "\n",
    "    #Erros do discriminador e gerador, e percentual de acerto no teste\n",
    "    errors_discrim = np.zeros((epochs))\n",
    "    errors_generator = np.zeros((epochs))\n",
    "    perc_discrim = np.zeros((epochs))\n",
    "\n",
    "    #Utilizado para a visualização de imagens não travar o treinamento\n",
    "    plt.ion()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        #Implementar o Treinamento da GAN conforme visto na aula 1. Primeiro treinar discriminador, \n",
    "        # depois treinar o gerador através da variável \"gan\". Para isso utilizar aa funcao generate_batch_discriminator\n",
    "        # -----------------\n",
    "        # Seu Codigo\n",
    "        # ---------------------\n",
    "        #periodicamente\n",
    "        if i%1000 == 0:\n",
    "            print(\"epoch: \"+str(i))\n",
    "            print_images(generator.predict(np.random.normal(0, 1, size=[50, dim_random_vector])))\n",
    "            print(\"Errors Discrimin: \" + str(errors_discrim[i]))\n",
    "            print(\"Errors Generator:\" + str(errors_generator[i]))\n",
    "            print(\"Perc Discrim:\" + str(perc_discrim[i]))\n",
    "train_gan(generator, discriminator, gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos avaliar a qualidade das instâncias geradas em comparação com as reais, também avaliar a progressão de erros para o gerador e discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(train_dataset[-25:])\n",
    "print_images(generator.predict(np.random.normal(0, 1, size=[25, dim_random_vector])))\n",
    "\n",
    "plt.plot(errors_generator, label='generator')\n",
    "plt.plot(errors_discrim, label='discriminator')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(perc_discrim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo parece bem efetivo em aprender como gerar alguns poucos números. Será que o modelo nessas mesmas configurações seria capaz de gerar todos os números de 0 a 9?\n",
    "\n",
    "Desenvolva uma função que separa a base de dados em subconjuntos que só possuem exemplos com 1 tipo de número, e treine uma GAN em cada um desses subconjuntos. Todos são capazes de gerar números realísticos? Ou só algum deles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos explorar agora um modelo gerador que também utiliza convoluções. Para isso utilize a classe [UpSampling2D](https://keras.io/api/layers/reshaping_layers/up_sampling2d/) para aumentar as dimensões da saída do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_generator_model(dim_random):\n",
    "    #Exemplo abaixo, sinta-se livre para alterá-lo\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128*7*7, input_dim=dim_random, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(28*28, activation='tanh'))\n",
    "    model.add(Reshape((28,28,1)))\n",
    "    return model\n",
    "\n",
    "generator = gan_generator_model(dim_random_vector)\n",
    "generator.summary()\n",
    "discriminator = gan_discriminator_model()\n",
    "opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "discriminator.summary()\n",
    "gan = define_gan(generator, discriminator)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar esse novo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(generator, discriminator, gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_images(train_dataset[-25:])\n",
    "print_images(generator.predict(np.random.normal(0, 1, size=[25, dim_random_vector])))\n",
    "\n",
    "plt.plot(errors_generator, label='generator')\n",
    "plt.plot(errors_discrim, label='discriminator')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(perc_discrim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça o mesmo que você fez para o primeiro modelo e treine um modelo separado para cada dígito possível. Qual modelo é mais efetivo para cada dígito?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
